{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1tdrqpZG_akKfKxGzn5ly_gTmTvOLu44c","authorship_tag":"ABX9TyOvYNC3n2WjK9mqf/J6hWc8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wEYsq5KVRIEg","executionInfo":{"status":"ok","timestamp":1734449948720,"user_tz":-330,"elapsed":988,"user":{"displayName":"Srusti Sulipalmath","userId":"10082315442818161473"}},"outputId":"bed25713-020e-4dd2-f94b-ad6b7f13be84"},"outputs":[{"output_type":"stream","name":"stdout","text":["Classifier Name:  K-Nearest Neighbors Score:  0.98\n","Classifier Name:  Linear SVM Score:  0.96\n","Classifier Name:  Decision Tree Score:  0.98\n","Classifier Name:  Multilayer Perceptron Score:  0.98\n","Classifier Name:  Gaussian Naive Bayes Score:  0.96\n","Classifier Name:  Random Forest Score:  0.98\n"]}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.neural_network import MLPClassifier\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.ensemble import RandomForestClassifier\n","\n","names = [\n","    \"K-Nearest Neighbors\",\n","    \"Linear SVM\",\n","    \"Decision Tree\",\n","    \"Multilayer Perceptron\",\n","    \"Gaussian Naive Bayes\",\n","    \"Random Forest\"\n","]\n","\n","classifiers = [\n","    KNeighborsClassifier(3),\n","    SVC(kernel=\"linear\", C=0.025),\n","    DecisionTreeClassifier(max_depth=5),\n","    MLPClassifier(alpha=1, max_iter=1000),\n","    GaussianNB(),\n","    RandomForestClassifier(n_estimators=100, max_depth=5, random_state=42)\n","]\n","df = pd.read_csv(\"/content/drive/MyDrive/Iris.csv\")\n","df.head()\n","df = df.drop(\"Id\", axis=1)\n","df.head()\n","\n","# Extract X and y as features and target\n","X = df.iloc[:, :-1]\n","X.head()\n","y = df.iloc[:, -1]\n","y.head()\n","\n","# Since target column is categorical, we will convert it to numerical using LabelEncoder\n","from sklearn.preprocessing import LabelEncoder\n","y = LabelEncoder().fit_transform(y)\n","y = pd.DataFrame(y)\n","y.head()\n","\n","# Train-test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n","\n","# Using a for loop fit all the classifiers to X_train and y_train and print the accuracy score of each classifier\n","for name, clf in zip(names, classifiers):\n","    clf.fit(X_train, y_train.values.ravel())\n","    score = clf.score(X_test, y_test)\n","    print(\"Classifier Name: \", name, \"Score: \", score)\n"]},{"cell_type":"code","source":[],"metadata":{"id":"N2zpZUmDRPNJ"},"execution_count":null,"outputs":[]}]}